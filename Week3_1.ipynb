{"cells":[{"cell_type":"markdown","metadata":{"id":"ugGR7pnI4WSe"},"source":["# Week3_1 Assignment\n","\n","## [BASIC](#Basic) \n","- 토크나이징이 완료된 위키 백과 코퍼스를 다운받고 **단어 사전을 구축하는 함수를 구현**할 수 있다.\n","- `Skip-Gram` 방식의 학습 데이터 셋을 생성하는 **Dataset과 Dataloader 클래스를 구현**할 수 있다.\n","- **Negative Sampling** 함수를 구현할 수 있다. \n","\n","\n","## [CHALLENGE](#Challenge)\n","- Skip-Gram을 학습 과정 튜토리얼을 따라하며, **Skip-Gram을 학습하는 클래스를 구현**할 수 있다. \n","\n","\n","## [ADVANCED](#Advanced)\n","- Skip-Gram 방식으로 word embedding을 학습하는 **Word2Vec 클래스를 구현**하고 실제로 학습할 수 있다.\n","- 학습이 완료된 word embedding을 불러와 **Gensim 패키지를 사용해 유사한 단어**를 뽑을 수 있다. \n","\n","### Reference\n","- [Skip-Gram negative sampling 한국어 튜토리얼](https://wikidocs.net/69141)\n","    - (참고) 위 튜토리얼에서는 target word와 context word 페어의 레이블은 1로, target word와 negative sample word 페어의 레이블은 0이 되도록 학습 데이터를 구현해 binary classification을 구현한다. 하지만 우리는 word2vec 논문 방식을 그대로 따르기 위해 label을 생성하지 않고 대신 loss 함수를 변행해서 binary classification을 학습할 것이다. "]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:29:36.641276Z","start_time":"2022-02-19T14:29:36.638642Z"},"id":"HlEy3xfY4WSh","executionInfo":{"status":"ok","timestamp":1646716958074,"user_tz":-540,"elapsed":593,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["import os \n","import sys\n","import pandas as pd\n","import numpy as np\n","import re\n","from typing import List, Dict\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:50:41.644583Z","start_time":"2022-02-19T12:50:41.642937Z"},"id":"cBrr7-gt4jnf"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:26:59.276355Z","start_time":"2022-02-19T14:26:58.411434Z"},"id":"6mC9lhsJ4WSh","executionInfo":{"status":"ok","timestamp":1646716973652,"user_tz":-540,"elapsed":8020,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import SGD\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:30:05.586472Z","start_time":"2022-02-19T14:30:05.583611Z"},"id":"17g7UZ5g4WSi","executionInfo":{"status":"ok","timestamp":1646716982242,"user_tz":-540,"elapsed":3,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["# seed\n","seed = 7777\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:30:06.721039Z","start_time":"2022-02-19T14:30:06.717559Z"},"id":"v3UlC7Jn4WSi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646716982756,"user_tz":-540,"elapsed":8,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"8486e7c6-9291-4632-d9b9-b972f997ff19"},"outputs":[{"output_type":"stream","name":"stdout","text":["# available GPUs : 1\n","GPU name : Tesla P100-PCIE-16GB\n","cuda\n"]}],"source":["# device type\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n","    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"k8sfv5KY4WSk"},"source":["## Basic"]},{"cell_type":"markdown","metadata":{"id":"sHs8_LU04WSj"},"source":["### 토크나이징이 완료된 위키 백과 코퍼스 다운로드 및 불용어 사전 크롤링\n","- 나의 구글 드라이브에 데이터를 다운받아 영구적으로 사용할 수 있도록 하자. \n","    - [데이터 다운로드 출처](https://ratsgo.github.io/embedding/downloaddata.html)\n","- 다운받은 데이터는 토크나이징이 완료된 상태이지만 불용어를 포함하고 있다. 따라서 향후 불용어를 제거하기 위해 불용어 사전을 크롤링하자. \n","    - [불용어 사전 출처](https://www.ranks.nl/stopwords/korean)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KYiz1fdNsAqp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646717242632,"user_tz":-540,"elapsed":24491,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"0a649833-9fac-491a-ed4d-b627576719f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Z2WZ0P4wsAqp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646717433872,"user_tz":-540,"elapsed":16,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"46b4252e-4497-4179-a22e-1cca511f315e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Pre-onboarding/week3/data\n"]}],"source":["# 데이터 다운로드할 위치 입력\n","%cd '/content/drive/MyDrive/Pre-onboarding/week3/data'"]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qC3UUsUAJcV","executionInfo":{"status":"ok","timestamp":1646717436434,"user_tz":-540,"elapsed":504,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"8558e19f-33ba-432a-9dea-c4a8ad179be5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Pre-onboarding/week3/data\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:27:15.633947Z","start_time":"2022-02-19T14:27:13.829982Z"},"id":"cTHCHmO24WSj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646717442527,"user_tz":-540,"elapsed":1486,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"c07a7f50-01b0-4877-d3bf-ec012a7bab18"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n","  InsecureRequestWarning)\n"]},{"output_type":"stream","name":"stdout","text":["# Korean stop words: 677\n"]}],"source":["# 한국어 불용어 리스트 크롤링\n","import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://www.ranks.nl/stopwords/korean\"\n","response = requests.get(url, verify = False)\n","\n","if response.status_code == 200:\n","    soup = BeautifulSoup(response.text,'html.parser')\n","    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n","    stop_words=[]\n","    for x in content.strings:\n","        x=x.strip()\n","        if x:\n","            stop_words.append(x)\n","    print(f\"# Korean stop words: {len(stop_words)}\")\n","else:\n","    print(response.status_code)"]},{"cell_type":"code","execution_count":16,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:27:11.886643Z","start_time":"2022-02-19T14:27:11.884858Z"},"id":"4QPBJ6UZ4WSj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646718063515,"user_tz":-540,"elapsed":38993,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"0ce563eb-e28a-4247-c2df-2545e7912451"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  tokenized.zip\n","   creating: tokenized/\n","  inflating: tokenized/korquad_mecab.txt  \n","  inflating: tokenized/wiki_ko_mecab.txt  \n","  inflating: tokenized/corpus_mecab_jamo.txt  \n","  inflating: tokenized/ratings_okt.txt  \n","  inflating: tokenized/ratings_khaiii.txt  \n","  inflating: tokenized/ratings_hannanum.txt  \n","  inflating: tokenized/ratings_soynlp.txt  \n","  inflating: tokenized/ratings_mecab.txt  \n","  inflating: tokenized/ratings_komoran.txt  \n"]}],"source":["# 데이터 다운로드\n","#!pip install gdown\n","#!gdown https://drive.google.com/u/0/uc?id=1Ybp_DmzNEpsBrUKZ1-NoPDzCMO39f-fx\n","!unzip tokenized.zip"]},{"cell_type":"code","execution_count":17,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:27:15.642775Z","start_time":"2022-02-19T14:27:15.635333Z"},"id":"3d0IqhDF4WSk","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1646718072031,"user_tz":-540,"elapsed":529,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"8950a9a6-285f-4947-bbfa-a3bbc667aaae"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'아'"]},"metadata":{},"execution_count":17}],"source":["stop_words[0]"]},{"cell_type":"markdown","metadata":{"id":"_t76Q1pQ4WSk"},"source":["### 단어 사전 구축 함수 구현 \n","- 문서 리스트를 입력 받아 사전을 생성하는 `make_vocab()` 함수를 구현하라.\n","- 함수 정의\n","    - 입력 매개변수\n","        - docs : 문서 리스트\n","        - min_count : 최소 단어 등장 빈도수 (단어 빈도가 `min_count` 미만인 단어는 사전에 포함하지 않음)\n","    - 조건\n","        - 문서 길이 제한\n","            - 단어 개수가 3개 이하인 문서는 처리하지 않음. (skip)\n","        - 사전에 포함되는 단어 빈도수 제한\n","            - 단어가 빈도가 `min_count` 미만은 단어는 사전에 포함하지 않음.\n","        - 불용어 제거 \n","            - 불용어 리스트에 포함된 단어는 제거 \n","    - 반환값 \n","        - word2count : 단어별 빈도 사전 (key: 단어, value: 등장 횟수)\n","        - wid2word : 단어별 인덱스(wid) 사전 (key: 단어 인덱스(int), value: 단어)\n","        - word2wid : 인덱스(wid)별 단어 사전 (key: 단어, value: 단어 인덱스(int))"]},{"cell_type":"code","source":["mypath = '/content/drive/MyDrive/Pre-onboarding/week3/data/tokenized/'"],"metadata":{"id":"vM1SV5hODcvE","executionInfo":{"status":"ok","timestamp":1646718268018,"user_tz":-540,"elapsed":7,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":87,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:01.637431Z","start_time":"2022-02-19T14:32:56.730711Z"},"id":"xkjqztIA4WSl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646729069442,"user_tz":-540,"elapsed":5419,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"586c2a36-0adf-4cd1-f141-3e17cc59497c"},"outputs":[{"output_type":"stream","name":"stderr","text":["311237it [00:04, 62351.92it/s]\n"]}],"source":["# 코퍼스 로드\n","\n","docs = []\n","\n","with open(mypath+'wiki_ko_mecab.txt','r') as f:\n","  for s in tqdm(f):\n","    docs.append(s)"]},{"cell_type":"code","execution_count":88,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:03.423002Z","start_time":"2022-02-19T14:33:03.419818Z"},"id":"WAKB6bbt4WSl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646729071319,"user_tz":-540,"elapsed":4,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"ef386b38-a944-4e01-f86d-cd427cd0697e"},"outputs":[{"output_type":"stream","name":"stdout","text":["# wiki documents: 311,237\n"]}],"source":["print(f\"# wiki documents: {len(docs):,}\")"]},{"cell_type":"code","execution_count":89,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:04.016885Z","start_time":"2022-02-19T14:33:03.962269Z"},"id":"-OI1MCXv4WSl","executionInfo":{"status":"ok","timestamp":1646729073138,"user_tz":-540,"elapsed":3,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["# 문서 개수를 500개로 줄임\n","docs=random.sample(docs,500)"]},{"cell_type":"code","source":["print(f\"# wiki documents: {len(docs):,}\")"],"metadata":{"id":"mP5wGu9YwDUw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646729077620,"user_tz":-540,"elapsed":571,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"1b030061-1b21-4bd9-dd86-8bbf2fc4089a"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["# wiki documents: 500\n"]}]},{"cell_type":"code","execution_count":91,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:26.392627Z","start_time":"2022-02-19T14:33:26.382358Z"},"id":"aJaEAVm9sAqv","executionInfo":{"status":"ok","timestamp":1646729081194,"user_tz":-540,"elapsed":514,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["# 문서 내 숫자, 영어 대소문자, 특수문자를 제거 (re package 사용)\n","docs = [re.sub('[^가-힣]', ' ', d) for d in docs]"]},{"cell_type":"code","source":["print(f\"Check : {docs[0][:1000]}\")"],"metadata":{"id":"sytiSICawMk5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646729082804,"user_tz":-540,"elapsed":4,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"042661fd-5b07-4f47-8f33-38e7d8477bb4"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Check : 가운 중학교              는 경기도 남양주시 가운동 에 있 는 공립 중학교 이 다           년   월   일 가운 중학교 설립 인가         년   월   일 초대 차 정숙 교장 취임         년   월   일 제   회 입학식     학급       명           년   월   일 제   회 졸업식         명 졸업           년   월   일 제   대 김 절용 교장 취임         년   월   일 제   회 졸업식         년   월   일 제     회 입학식 분류   남양주시 의 중학교 분류           년 개교 \n"]}]},{"cell_type":"code","source":["len(docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"roztdQmavS_z","executionInfo":{"status":"ok","timestamp":1646729755059,"user_tz":-540,"elapsed":1155,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"d15e69b6-7fac-4a15-a959-d9f1febdbda9"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","execution_count":154,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:27.904880Z","start_time":"2022-02-19T14:33:27.899620Z"},"id":"OAkkQsvO4WSl","executionInfo":{"status":"ok","timestamp":1646731681065,"user_tz":-540,"elapsed":610,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["def make_vocab(docs:List[str], min_count:int):\n","    \"\"\"\n","    'docs'문서 리스트를 입력 받아 단어 사전을 생성.\n","    \n","    return \n","        - word2count : 단어별 빈도 사전\n","        - wid2word : 단어별 인덱스(wid) 사전 \n","        - word2wid : 인덱스(wid)별 단어 사전\n","    \"\"\"\n","\n","    word2count = dict()\n","    word2id = dict()\n","    id2word = dict()\n","\n","    _word2count = dict()\n","    vocab_list = []\n","    for doc in tqdm(docs):\n","        word_list = doc.split()\n","\n","        # 1. 문서 길이 제한\n","        if len(word_list) <= 3:\n","          continue\n","\n","        # 2. 임시 딕셔너리(_word2count)에 단어별 등장 빈도 기록\n","        freq = 1\n","        for word in word_list:\n","          if word not in list(_word2count.keys()):\n","            _word2count.update({word:freq})\n","          else:\n","            _word2count[word] += 1\n","\n","        # 3. 불용어 제거\n","        result = []\n","        for word in word_list: \n","            if word not in stop_words: \n","                result.append(word)\n","        vocab_list.append(result)\n","\n","    vocab_set = set(sum(vocab_list, []))\n","\n","    # 4. 토큰 최소 빈도를 만족하는 토큰만 사전에 추가\n","    for word in vocab_set:\n","      if _word2count[word] < min_count:\n","        continue\n","\n","      if word not in list(word2count.keys()):\n","        word2count[word] = _word2count.get(word)\n","\n","    # 5. wid2word : 단어별 인덱스(wid) 사전 (key: 단어 인덱스(int), value: 단어)\n","    word2id = {w: idx for (idx, w) in enumerate(word2count)}\n","\n","    # 6. word2wid : 인덱스(wid)별 단어 사전 (key: 단어, value: 단어 인덱스(int))\n","    id2word = {idx: w for (idx, w) in enumerate(word2count)}\n","\n","    return word2count, word2id, id2word"]},{"cell_type":"code","execution_count":155,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:30.157872Z","start_time":"2022-02-19T14:33:28.473330Z"},"id":"ieS5SiQx4WSm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646731749684,"user_tz":-540,"elapsed":63784,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"3e138d7b-7c6b-4597-8976-ebd5777bd2e4"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [01:02<00:00,  8.04it/s]\n"]}],"source":["word2count, word2id, id2word = make_vocab(docs, min_count=5)"]},{"cell_type":"code","execution_count":156,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:30.754722Z","start_time":"2022-02-19T14:33:30.752115Z"},"id":"cT1MRN1EJtx6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646731769221,"user_tz":-540,"elapsed":660,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"f9a97ce0-1947-41a8-b81f-4e023c08b264"},"outputs":[{"output_type":"stream","name":"stdout","text":["138,478\n"]}],"source":["doc_len = sum(word2count.values()) # 문서 내 모든 단어의 개수 (단어별 등장 빈도의 총 합)\n","print(f\"{doc_len:,}\")"]},{"cell_type":"code","execution_count":157,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:32.916830Z","start_time":"2022-02-19T14:33:32.914355Z"},"id":"e_1MneB54WSm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646731769799,"user_tz":-540,"elapsed":4,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"ecdd6e81-ac75-4071-b064-b7f72b29c9ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["# unique word : 5,105\n"]}],"source":["print(f\"# unique word : {len(word2id):,}\")"]},{"cell_type":"markdown","metadata":{"id":"gHxtZqtk4WSm"},"source":["### Dataset 클래스 구현\n","- Skip-Gram 방식의 학습 데이터 셋(`Tuple(target_word, context_word)`)을 생성하는 `CustomDataset` 클래스를 구현하라.\n","- 클래스 정의\n","    - 생성자(`__init__()` 함수) 입력 매개변수\n","        - docs: 문서 리스트\n","        - word2id: 단어별 인덱스(wid) 사전\n","        - window_size: Skip-Gram의 윈도우 사이즈\n","    - 메소드\n","        - `make_pair()`\n","            - 문서를 단어로 쪼개고, 사전에 존재하는 단어들만 단어 인덱스로 변경\n","            - Skip-gram 방식의 `(target_word, context_word)` 페어(tuple)들을 `pairs` 리스트에 담아 반환\n","        - `__len__()`\n","            - `pairs` 리스트의 개수 반환\n","        - `__getitem__(index)`\n","            - `pairs` 리스트를 인덱싱\n","    - 주의 사항\n","        - `nn.Module`를 부모 클래스로 상속 받음 \n"]},{"cell_type":"code","source":["word2id.get('가격')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-SxK0c-b8REX","executionInfo":{"status":"ok","timestamp":1646733121085,"user_tz":-540,"elapsed":428,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"9ee0ac71-5368-4b36-937b-549fb82c7db8"},"execution_count":159,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2423"]},"metadata":{},"execution_count":159}]},{"cell_type":"code","execution_count":161,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:38.111290Z","start_time":"2022-02-19T14:33:38.104531Z"},"id":"UPiLcYCZ4WSm","executionInfo":{"status":"ok","timestamp":1646734388252,"user_tz":-540,"elapsed":593,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    \"\"\"\n","    문서 리스트를 받아 skip-gram 방식의 (target_word, context_word) 데이터 셋을 생성\n","    \"\"\"\n","    def __init__(self, docs:List[str], word2id:Dict[str,int], window_size:int=5):\n","        self.docs = docs\n","        self.word2id = word2id\n","        self.window_size = window_size\n","        self.pairs = self.make_pair()\n","    \n","    def make_pair(self):\n","        \"\"\"\n","        (target, context) 형식의 Skip-gram pair 데이터 셋 생성\n","        \"\"\"\n","        pairs = []\n","\n","        vocab = []\n","        for doc in tqdm(docs):\n","          word_list = doc.split()   # 문서를 단어로 쪼갠다.\n","          for word in word_list:\n","            if word not in (list(word2count.keys())):   # 사전에 존재하는 단어인지 확인한다.\n","              continue\n","            word = word2id.get(word)    # 단어 인덱스로 변경\n","            vocab.append(word)\n","\n","        for i, wid in enumerate(vocab):\n","          window_start = max(0, i - self.window_size)\n","          window_end = min(len(vocab), i + self.window_size + 1)\n","          for j in range(window_start, window_end):\n","              if j != i:\n","                  wj = vocab[j]\n","                  if not wj:\n","                      continue\n","                  pairs.append((wid, wj))\n","\n","        return pairs\n","    \n","        \n","    def __len__(self):\n","        return len(self.pairs)\n","    \n","    def __getitem__(self, idx):\n","        return self.pairs[idx]"]},{"cell_type":"code","execution_count":162,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:38.945361Z","start_time":"2022-02-19T14:33:38.385577Z"},"id":"YntOw2q94WSm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646734423002,"user_tz":-540,"elapsed":29077,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"36dde6bf-94ca-4ba8-e994-6e8aad245b9a"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:28<00:00, 17.52it/s]\n"]}],"source":["dataset = CustomDataset(docs, word2id, window_size=5)"]},{"cell_type":"code","execution_count":163,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:38.949614Z","start_time":"2022-02-19T14:33:38.946663Z"},"id":"-RpNbAjk4WSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646734430341,"user_tz":-540,"elapsed":527,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"30b48c65-0511-460a-ea5f-7bd1162c538d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1384640"]},"metadata":{},"execution_count":163}],"source":["len(dataset)"]},{"cell_type":"code","execution_count":164,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:43.072635Z","start_time":"2022-02-19T14:33:43.069526Z"},"id":"1FBwcL4H4WSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646734433058,"user_tz":-540,"elapsed":421,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"9f36604f-33b4-42dc-811c-c10c1f165c0d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1947, 496)"]},"metadata":{},"execution_count":164}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":165,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:33:51.040595Z","start_time":"2022-02-19T14:33:51.031473Z"},"id":"wTAwTjKk4WSn","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646734518220,"user_tz":-540,"elapsed":635,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"e50f20d5-e43c-4b47-f956-bdd229179ea6"},"outputs":[{"output_type":"stream","name":"stdout","text":["(중학교, 는)\n","(중학교, 경기도)\n","(중학교, 남양주시)\n","(중학교, 있)\n","(중학교, 는)\n","(는, 중학교)\n","(는, 경기도)\n","(는, 남양주시)\n","(는, 있)\n","(는, 는)\n","(는, 공립)\n","(경기도, 중학교)\n","(경기도, 는)\n","(경기도, 남양주시)\n","(경기도, 있)\n","(경기도, 는)\n","(경기도, 공립)\n","(경기도, 중학교)\n","(남양주시, 중학교)\n","(남양주시, 는)\n","(남양주시, 경기도)\n","(남양주시, 있)\n","(남양주시, 는)\n","(남양주시, 공립)\n","(남양주시, 중학교)\n","(남양주시, 다)\n","(있, 중학교)\n","(있, 는)\n","(있, 경기도)\n","(있, 남양주시)\n","(있, 는)\n","(있, 공립)\n","(있, 중학교)\n","(있, 다)\n","(있, 중학교)\n","(는, 중학교)\n","(는, 는)\n","(는, 경기도)\n","(는, 남양주시)\n","(는, 있)\n","(는, 공립)\n","(는, 중학교)\n","(는, 다)\n","(는, 중학교)\n","(는, 설립)\n","(공립, 는)\n","(공립, 경기도)\n","(공립, 남양주시)\n","(공립, 있)\n","(공립, 는)\n","(공립, 중학교)\n","(공립, 다)\n","(공립, 중학교)\n","(공립, 설립)\n","(공립, 인가)\n","(중학교, 경기도)\n","(중학교, 남양주시)\n","(중학교, 있)\n","(중학교, 는)\n","(중학교, 공립)\n","(중학교, 다)\n","(중학교, 중학교)\n","(중학교, 설립)\n","(중학교, 인가)\n","(중학교, 초대)\n","(다, 남양주시)\n","(다, 있)\n","(다, 는)\n","(다, 공립)\n","(다, 중학교)\n","(다, 중학교)\n","(다, 설립)\n","(다, 인가)\n","(다, 초대)\n","(다, 차)\n","(중학교, 있)\n","(중학교, 는)\n","(중학교, 공립)\n","(중학교, 중학교)\n","(중학교, 다)\n","(중학교, 설립)\n","(중학교, 인가)\n","(중학교, 초대)\n","(중학교, 차)\n","(중학교, 교장)\n","(설립, 는)\n","(설립, 공립)\n","(설립, 중학교)\n","(설립, 다)\n","(설립, 중학교)\n","(설립, 인가)\n","(설립, 초대)\n","(설립, 차)\n","(설립, 교장)\n","(설립, 취임)\n","(인가, 공립)\n","(인가, 중학교)\n","(인가, 다)\n","(인가, 중학교)\n","(인가, 설립)\n"]}],"source":["# verify (target word, context word)\n","for i, pair in enumerate(dataset):\n","    if i==100:\n","        break\n","    print(f\"({id2word[pair[0]]}, {id2word[pair[1]]})\")\n","    "]},{"cell_type":"markdown","metadata":{"id":"P0Z50-Dr4WSn"},"source":["### 위에서 생성한 `dataset`으로 DataLoader  객체 생성\n","- `DataLoader` 클래스로 `train_dataloader`객체를 생성하라. \n","    - 생성자 매개변수와 값\n","        - dataset = 위에서 생성한 dataset\n","        - batch_size = 64\n","        - shuffle = True"]},{"cell_type":"code","execution_count":166,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:02.645176Z","start_time":"2022-02-19T14:34:02.642780Z"},"id":"GXcAvFB14WSn","executionInfo":{"status":"ok","timestamp":1646735409619,"user_tz":-540,"elapsed":891,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["train_batch_size = 64\n","\n","train_dataloader = DataLoader(\n","    dataset, \n","    batch_size = train_batch_size, \n","    shuffle = True)"]},{"cell_type":"code","execution_count":167,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:02.777322Z","start_time":"2022-02-19T14:34:02.774335Z"},"id":"4Yfcwi_14WSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646735411395,"user_tz":-540,"elapsed":489,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"cfab0090-3378-4886-d510-14812706b3e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["21635"]},"metadata":{},"execution_count":167}],"source":["len(train_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"eTs16gsU4WSn"},"source":["### Negative Sampling 함수 구현\n","- Skip-Gram은 복잡도를 줄이기 위한 방법으로 negative sampling을 사용한다. \n","- `sample_table`이 다음과 같이 주어졌을 때, sample_table에서 랜덤으로 값을 뽑아 (batch_size, n_neg_sample) shape의 matrix를 반환하는 `get_neg_v_negative_sampling()`함수를 구현하라. \n","- Sample Table은 negative distribution을 따른다. \n","    - [negative distribution 설명](https://aegis4048.github.io/optimize_computational_efficiency_of_skip-gram_with_negative_sampling#How-are-negative-samples-drawn?)\n","- 함수 정의\n","    - 입력 매개변수\n","        - batch_size : 배치 사이즈, matrix의 row 개수 \n","        - n_neg_sample : negative sample의 개수, matrix의 column 개수\n","    - 반환값 \n","        - neg_v : 추출된 negative sample (2차원의 리스트)\n"]},{"cell_type":"code","execution_count":168,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:11.397509Z","start_time":"2022-02-19T14:34:11.386389Z"},"id":"PUqIB6dH4WSn","scrolled":true,"executionInfo":{"status":"ok","timestamp":1646735586437,"user_tz":-540,"elapsed":601,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["# negative sample을 추출할 sample table 생성 (해당 코드를 참고)\n","sample_table = []\n","sample_table_size = doc_len\n","\n","# noise distribution 생성\n","alpha = 3/4\n","frequency_list = np.array(list(word2count.values())) ** alpha\n","Z = sum(frequency_list)\n","ratio = frequency_list/Z\n","negative_sample_dist = np.round(ratio*sample_table_size)\n","\n","for wid, c in enumerate(negative_sample_dist):\n","    sample_table.extend([wid]*int(c))"]},{"cell_type":"code","execution_count":169,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:11.508414Z","start_time":"2022-02-19T14:34:11.505464Z"},"id":"Wdu8qK8x4WSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646735588051,"user_tz":-540,"elapsed":3,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"b5685178-bb63-4647-e963-9343f15704fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["138162"]},"metadata":{},"execution_count":169}],"source":["len(sample_table)"]},{"cell_type":"code","execution_count":175,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:11.656046Z","start_time":"2022-02-19T14:34:11.653325Z"},"id":"mQIVrOIR4WSn","executionInfo":{"status":"ok","timestamp":1646737561370,"user_tz":-540,"elapsed":511,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["def get_neg_v_negative_sampling(batch_size:int, n_neg_sample:int):\n","    \"\"\"\n","    위에서 정의한 sample_table에서 (batch_size, n_neg_sample) shape만큼 랜덤 추출해 \"네거티브 샘플 메트릭스\"를 생성\n","    np.random.choice() 함수 활용 (위에서 정의한 sample_table을 함수의 argument로 사용)\n","    \"\"\"\n","    neg_v = np.random.choice(sample_table, size = (batch_size,n_neg_sample))\n","\n","    return neg_v"]},{"cell_type":"code","execution_count":177,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:12.345976Z","start_time":"2022-02-19T14:34:12.333448Z"},"id":"8wwT4Af04WSo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646737570049,"user_tz":-540,"elapsed":585,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"c8ccf842-93ed-4e0f-cb18-5d23a9c6b68e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2303, 5043, 2869, 1866, 2962],\n","       [1965, 3389, 1645, 3313, 4894],\n","       [2920, 1324,  512, 4844, 3925],\n","       [ 204, 2329, 1699, 1886, 5037]])"]},"metadata":{},"execution_count":177}],"source":["get_neg_v_negative_sampling(4, 5)"]},{"cell_type":"markdown","metadata":{"id":"nLnDXPvJ4WSo"},"source":["## Challenge"]},{"cell_type":"markdown","metadata":{"id":"B5UubCzK4WSo"},"source":["### 미니 튜토리얼\n","- 아래 튜토리얼을 따라하며 Skip-Gram 모델의 `forward` 및 `loss` 연산 방식을 이해하자\n","- Reference\n","    - [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n","    - [torch bmm](https://pytorch.org/docs/stable/generated/torch.bmm.html)\n","    - [Skip-Gram negative sampling loss function 설명 영문 블로그](https://aegis4048.github.io/optimize_computational_efficiency_of_skip-gram_with_negative_sampling#Derivation-of-Cost-Function-in-Negative-Sampling)\n","    - [Skip-Gram negative sampling loss function 설명 한글 블로그](https://reniew.github.io/22/)"]},{"cell_type":"code","execution_count":178,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:51:46.954048Z","start_time":"2022-02-19T12:51:46.951529Z"},"id":"IAR68hsY4WSo","executionInfo":{"status":"ok","timestamp":1646737610858,"user_tz":-540,"elapsed":435,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["# hyper parameter example\n","emb_size = 30000 # vocab size\n","emb_dimension = 300 # word embedding 차원\n","n_neg_sample = 5\n","batch_size = 32"]},{"cell_type":"code","execution_count":179,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:51:49.340056Z","start_time":"2022-02-19T12:51:47.300999Z"},"id":"zzOsVUn94WSo","executionInfo":{"status":"ok","timestamp":1646737623272,"user_tz":-540,"elapsed":11091,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["# 1. Embedding Matrix와 Context Matrix를 생성\n","u_embedding = nn.Embedding(emb_size, emb_dimension, sparse=True).to(device)\n","v_embedding = nn.Embedding(emb_size, emb_dimension, sparse=True).to(device)"]},{"cell_type":"code","execution_count":180,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:51:49.352240Z","start_time":"2022-02-19T12:51:49.341437Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":916,"status":"ok","timestamp":1646737626393,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"},"user_tz":-540},"id":"I7J_ADc44WSo","outputId":"2139665b-8ea8-4c25-c18f-5eea1b7d9f44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Target word idx : tensor([24460, 10634,  2864, 23952,  3320, 15187, 19625, 26546, 27339,  3920,\n","        25847,  6023,  5055,  7070,  6291, 10245, 15926,   641, 20178,  4565,\n","         4784, 26715, 16955, 28742, 17947, 19774,  8065, 22605,  3061, 28965,\n","         3056, 17963]) Pos context word idx : tensor([23224,  5636, 23712,  5234,  3991, 17897, 25123, 17938, 19634, 24228,\n","          693,   799, 25457,  1308, 28935, 25696,  5601, 23878,  8312,  1292,\n","        21380, 16974,  9318,  9578, 12915, 29271, 26465, 20572,  2362, 25929,\n","        19754, 29080]) Neg context word idx : [[1856 4166 2659 2343 4116]\n"," [3970 1916 4272  719 4829]\n"," [1142  794 3882 1266 2407]\n"," [4144 1672  789 4747 2855]\n"," [1961 3007 2120 3341 4359]\n"," [1543 2679 4454 1285 3241]\n"," [1555  639 1853 5027 3922]\n"," [4956  496 3022  867 1683]\n"," [3522 2390 4902 2293 4152]\n"," [2400  736 2792 2152 4650]\n"," [3377  694 3094 1267 2793]\n"," [4998 3126  838 3866 1856]\n"," [3563 5004 4234 3759 2955]\n"," [2547 2887 4711  612 2529]\n"," [ 628  376 4586 3326 1019]\n"," [3347 2261 2032 3701 2610]\n"," [2226 3004 4619 4267 2981]\n"," [4407  876 3418 4402 3291]\n"," [ 451 2221 4727 5048  864]\n"," [1138 4034 4252 3961 1027]\n"," [2834 4004  269 4009 4623]\n"," [2340 4358 1239  830 3820]\n"," [ 344 2935 3317  454  206]\n"," [2216 1322 2544 2993 1082]\n"," [5079 3895 1277 1128  496]\n"," [1503 2808  225 1195 1128]\n"," [1247 4765 4371 3947 2091]\n"," [4305  491 1879 2927  372]\n"," [ 173 2734 1521 3249  294]\n"," [ 913 4917 4426 4824  302]\n"," [3350 2676 2254 4619 5012]\n"," [2349 1919  247 3563 2448]]\n","\n"]}],"source":["# 2. wid(단어 인덱스)를 임의로 생성\n","pos_u = torch.randint(high = emb_size, size = (batch_size,))\n","pos_v = torch.randint(high = emb_size, size = (batch_size,))\n","neg_v = get_neg_v_negative_sampling(batch_size, n_neg_sample)\n","print(f\"Target word idx : {pos_u} Pos context word idx : {pos_v} Neg context word idx : {neg_v}\\n\")"]},{"cell_type":"code","execution_count":181,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:51:49.364020Z","start_time":"2022-02-19T12:51:49.353486Z"},"id":"4iEG0nCZ4WSo","executionInfo":{"status":"ok","timestamp":1646737636159,"user_tz":-540,"elapsed":432,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["# 3. tensor로 변환\n","pos_u = Variable(torch.LongTensor(pos_u)).to(device)\n","pos_v = Variable(torch.LongTensor(pos_v)).to(device)\n","neg_v = Variable(torch.LongTensor(neg_v)).to(device)"]},{"cell_type":"code","execution_count":182,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:51:51.391896Z","start_time":"2022-02-19T12:51:51.387084Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646737637873,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"},"user_tz":-540},"id":"gqbNbajG4WSo","outputId":"3e63c3b7-c8fe-4ee7-b646-5de97559abe4"},"outputs":[{"output_type":"stream","name":"stdout","text":["shape of pos_u embedding : torch.Size([32, 300])\n"," shape of pos_v embedding : torch.Size([32, 300])\n"," shape of neg_v embedding : torch.Size([32, 5, 300])\n"]}],"source":["# 4. wid로 각각의 embedding matrix에서 word embedding 값을 가져오기\n","pos_u = u_embedding(pos_u)\n","pos_v = v_embedding(pos_v)\n","neg_v = v_embedding(neg_v)\n","print(f\"shape of pos_u embedding : {pos_u.shape}\\n shape of pos_v embedding : {pos_v.shape}\\n shape of neg_v embedding : {neg_v.shape}\")\n"]},{"cell_type":"code","execution_count":183,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:51:53.121477Z","start_time":"2022-02-19T12:51:52.646148Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646737639539,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"},"user_tz":-540},"id":"uDWUrSwo4WSo","outputId":"16d2314f-a1e4-4ff9-baa4-270eca0f4d36"},"outputs":[{"output_type":"stream","name":"stdout","text":["shape of pos logits : torch.Size([32])\n","\n","shape of logits : torch.Size([32, 5])\n"]}],"source":["# 5. dot product \n","pos_score = torch.mul(pos_u, pos_v) # 행렬 element-wise 곱\n","pos_score = torch.sum(pos_score, dim=1)\n","print(f\"shape of pos logits : {pos_score.shape}\\n\")\n","\n","neg_score = torch.bmm(neg_v, pos_u.unsqueeze(dim=2)).squeeze()\n","print(f\"shape of logits : {neg_score.shape}\")"]},{"cell_type":"code","execution_count":184,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T12:51:53.670418Z","start_time":"2022-02-19T12:51:53.665671Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":664,"status":"ok","timestamp":1646737648044,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"},"user_tz":-540},"id":"adOpcoL54WSo","outputId":"1e915f1d-f1ad-44f0-c6fa-0a52d567c8ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["pos logits : -241.4199676513672\n","neg logits : -1224.525634765625\n","Loss : 1465.945556640625\n"]}],"source":["# 6. loss 구하기\n","pos_score = F.logsigmoid(pos_score)\n","neg_score = F.logsigmoid(-1*neg_score) # negative의 logit은 minimize 하기 위해 -1 곱함\n","print(f\"pos logits : {pos_score.sum()}\")\n","print(f\"neg logits : {neg_score.sum()}\")\n","loss = -1 * (torch.sum(pos_score) + torch.sum(neg_score))\n","print(f\"Loss : {loss}\")"]},{"cell_type":"markdown","metadata":{"id":"muEceOGZ4WSo"},"source":["### Skip-gram 클래스 구현\n","- Skip-Gram 방식으로 단어 embedding을 학습하는 `SkipGram` 클래스를 구현하라.\n","- 클래스 정의\n","    - 생성자(`__init__()` 함수) 입력 매개변수\n","        - `vocab_size` : 사전내 단어 개수\n","        - `emb_dimension` : 엠베딩 크기\n","        - `device` : 연산 장치 종류\n","    - 생성자에서 생성해야할 변수 \n","        - `vocab_size` : 사전내 단어 개수\n","        - `emb_dimension` : 엠베딩 크기\n","        - `u_embedding` : (vocab_size, emb_dimension) 엠베딩 메트릭스 (target_word)\n","        - `v_embedding` : (vocab_size, emb_dimension) 엠베딩 메트릭스 (context_word)\n","    - 메소드\n","        - `init_embedding()` (제공됨)\n","            - 엠베딩 메트릭스 값을 초기화\n","        - `forward()`\n","            - 위 튜토리얼과 같이 dot product를 수행한 후 score를 생성\n","            - loss를 반환 (loss 설명 추가)\n","        - `save_emedding()` (제공됨)\n","            - `u_embedding`의 단어 엠베딩 값을 단어 별로 파일에 저장\n","    - 주의 사항     \n","        - `nn.Module`를 부모 클래스로 상속 받음 "]},{"cell_type":"code","execution_count":185,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:15.731306Z","start_time":"2022-02-19T14:34:15.721129Z"},"id":"pnmMamP44WSo","executionInfo":{"status":"ok","timestamp":1646739188527,"user_tz":-540,"elapsed":484,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["class SkipGram(nn.Module):\n","    def __init__(self, vocab_size:int, emb_dimension:int, device:str):\n","        super(SkipGram, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.emb_dimension = emb_dimension\n","        self.u_embedding = nn.Embedding(vocab_size, emb_dimension, sparse=True).to(device)\n","        self.v_embedding = nn.Embedding(vocab_size, emb_dimension, sparse=True).to(device)\n","        self.init_embedding()\n","    \n","\n","    def init_embedding(self):\n","        \"\"\"\n","        u_embedding과 v_embedding 메트릭스 값을 초기화\n","        \"\"\"\n","        initrange = 0.5 / self.emb_dimension\n","        self.u_embedding.weight.data.uniform_(-initrange, initrange)\n","        self.v_embedding.weight.data.uniform_(-0, 0)\n","    \n","    \n","    def forward(self, pos_u, pos_v, neg_v):\n","        \"\"\"\n","        dot product를 수행한 후 score를 생성\n","        loss 반환\n","        \"\"\"    \n","\n","        # 각각의 embedding matrix에서 word embedding 값을 가져오기\n","        pos_u = u_embedding(pos_u)\n","        pos_v = v_embedding(pos_v)\n","        neg_v = v_embedding(neg_v)\n","\n","        # dot product \n","        pos_score = torch.mul(pos_u, pos_v) # 행렬 element-wise 곱\n","        pos_score = torch.sum(pos_score, dim=1)\n","        neg_score = torch.bmm(neg_v, pos_u.unsqueeze(dim=2)).squeeze()\n","        \n","        # loss 구하기\n","\n","        pos_score = F.logsigmoid(pos_score)\n","        neg_score = F.logsigmoid(-1*neg_score) # negative의 logit은 minimize 하기 위해 -1 곱함\n","        loss = -1 * (torch.sum(pos_score) + torch.sum(neg_score))\n","\n","        return loss\n","    \n","    def save_embedding(self, id2word, file_name, use_cuda):\n","        \"\"\"\n","        'file_name' 위치에 word와 word_embedding을 line-by로 저장\n","        파일의 첫 줄은 '단어 개수' 그리고 '단어 embedding 사이즈' 값을 입력해야 함\n","        \"\"\"\n","        if use_cuda: # parameter를 gpu 메모리에서 cpu 메모리로 옮김\n","            embedding = self.u_embedding.weight.cpu().data.numpy()\n","        else:\n","            embedding = self.u_embedding.weight.data.numpy()\n","\n","        with open(file_name, 'w') as writer:\n","            # 파일의 첫 줄은 '단어 개수' 그리고 '단어 embedding 사이즈' 값을 입력해야 함\n","            writer.write(f\"{len(id2word)} {embedding.shape[-1]}\\n\")\n","            \n","            for wid, word in id2word.items():\n","                e = embedding[wid]\n","                e = \" \".join([str(e_) for e_ in e])\n","                writer.write(f\"{word} {e}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"RqqMo0zL4WSo"},"source":["## Advanced"]},{"cell_type":"markdown","metadata":{"id":"wSWd5gV24WSp"},"source":["### Skip-Gram 방식의  Word2Vec 클래스 구현\n","- Skip-Gram 방식으로 단어 embedding을 학습하는 `Word2Vec` 클래스를 구현하라.\n","- 클래스 정의\n","    - 생성자(`__init__()`) 입력 매개 변수\n","        - `input_file` : 학습할 문서 리스트\n","        - `output_file_name` : 학습된 word embedding을 저장할 파일 위치\n","        - `device` : 연상 장치 종류\n","        - `emb_dimension` : word embedding 차원\n","        - `batch_size` : 학습 배치 사이즈\n","        - `window_size` : skip-gram 윈도우 사이즈 (context word 개수를 결정)\n","        - `n_neg_sample` : negative sample 개수\n","        - `iteration` : 학습 반복 횟수\n","        - `lr` : learning rate\n","        - `min_count` : 사전에 추가될 단어의 최소 등장 빈도\n","    - 생성자에서 생성해야 할 변수 \n","        - `docs` : 학습할 문서 리스트\n","        - `output_file_name` : 학습된 word embedding을 저장할 파일 위치\n","        - `word2count`, `word2id`, `id2word` : 위에서 구현한 `make_vocab()` 함수의 반환 값\n","        - `device` : 연산 장치 종류\n","        - `emb_size` : vocab의 (unique한) 단어 종류 \n","        - `emb_dimension` : word embedding 차원\n","        - `batch_size` : 학습 배치 사이즈\n","        - `window_size` : skip-gram 윈도우 사이즈 (context word 개수를 결정)\n","        - `n_neg_sample` : negative sample 개수\n","        - `iteration` : 학습 반복 횟수\n","        - `lr` : learning rate\n","        - `model` : `SkipGram` 클래스의 인스턴스\n","        - `optimizer` : `SGD` 클래스의 인스턴스\n","    - 메소드\n","        - `train()`\n","            - 입력 매개변수 \n","                - `train_dataloader`\n","            - Iteration 횟수만큼 input_file 학습 데이터를 학습한다. 매 epoch마다 for loop 돌면서 batch 단위 학습 데이터를 skip gram 모델에 학습함. 학습이 끝나면 word embedding을 output_file_name 파일에 저장.\n","- Reference\n","    - [Optimizer - SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"]},{"cell_type":"code","execution_count":207,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:20.503555Z","start_time":"2022-02-19T14:34:20.491585Z"},"id":"Td-GQrqI4WSp","executionInfo":{"status":"ok","timestamp":1646743348747,"user_tz":-540,"elapsed":477,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["class Word2Vec:\n","    def __init__(self, \n","                input_file: List[str],\n","                output_file_name: str,\n","                 device: str,\n","                 emb_dimension=300,\n","                 batch_size = 64,\n","                 window_size=5,\n","                 n_neg_sample = 5,\n","                 iteration=1,\n","                 lr = 0.02,\n","                 min_count=5):\n","        self.docs = input_file\n","        self.output_file_name = output_file_name\n","        self.word2count, self.word2id, self.id2word = make_vocab(docs, min_count)\n","        self.device = device\n","        self.emb_size = len(self.word2id)\n","        self.emb_dimension = emb_dimension\n","        self.batch_size = batch_size\n","        self.window_size = window_size\n","        self.n_neg_sample = n_neg_sample\n","        self.iteration = iteration\n","        self.lr = lr\n","        self.model = SkipGram(self.emb_size, self.emb_dimension, self.device)\n","        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr) # torch.optim.SGD 클래스 사용\n","\n","        # train() 함수에서 만든 임베딩 결과 파일들을 저장할 폴더 생성 (os.makedirs 사용)\n","        os.makedirs('./data', exist_ok=True)\n","        \n","    \n","    def train(self, train_dataloader):\n","        \n","        # lr 값을 조절하는 스케줄러 인스턴스 변수를 생성\n","        self.scheduler = get_linear_schedule_with_warmup(\n","            optimizer = self.optimizer,\n","            num_warmup_steps=0,\n","            num_training_steps=(len(train_dataloader) * self.iteration)\n","        )\n","        \n","        for epoch in range(self.iteration):\n","            \n","            print(f\"*****Epoch {epoch} Train Start*****\")\n","            print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n","            total_loss, batch_loss, batch_step = 0,0,0\n","\n","            for step, batch in enumerate(train_dataloader):\n","                batch_step+=1\n","\n","                pos_u, pos_v = batch\n","                # negative data 생성\n","                neg_v = get_neg_v_negative_sampling(pos_u.shape[0], self.n_neg_sample)\n","                \n","                # 데이터를 tensor화 & device 설정\n","                pos_u = Variable(torch.LongTensor(pos_u)).to(device)\n","                pos_v = Variable(torch.LongTensor(pos_v)).to(device)\n","                neg_v = Variable(torch.LongTensor(neg_v)).to(device)\n","\n","                # model의 gradient 초기화\n","                self.model.zero_grad() \n","\n","                # optimizer의 gradient 초기화\n","                self.optimizer.zero_grad()\n","\n","                # forward\n","                loss = self.model.forward(pos_u, pos_v, neg_v)\n","\n","                # loss 계산\n","                loss.backward()\n","\n","                # optimizer 업데이트\n","                self.optimizer.step()\n","\n","                # scheduler 업데이트\n","                self.scheduler.step()\n","\n","                batch_loss += loss.item()\n","                total_loss += loss.item()\n","                \n","                if (step%500 == 0) and (step!=0):\n","                    print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {self.optimizer.param_groups[0]['lr']:.4f}\")\n","                    # 변수 초기화    \n","                    batch_loss, batch_step = 0,0\n","            \n","            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n","            print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n","            \n","            print(f\"*****Epoch {epoch} Saving Embedding...*****\")\n","            self.model.save_embedding(self.id2word, os.path.join(self.output_file_name, f'w2v_{epoch}.txt'), True if 'cuda' in self.device.type else False)\n","            print(f\"*****Epoch {epoch} Embedding Saved at {os.path.join(self.output_file_name, f'w2v_{epoch}.txt')}*****\\n\")"]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQ5is8ifjJZF","executionInfo":{"status":"ok","timestamp":1646743298930,"user_tz":-540,"elapsed":560,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"d674fbce-d08a-432c-ffea-e5d46dc4bf5a"},"execution_count":206,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Pre-onboarding/week3/data\n"]}]},{"cell_type":"code","execution_count":208,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:29.561892Z","start_time":"2022-02-19T14:34:26.103659Z"},"id":"Ywx9R8n24WSp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646743430265,"user_tz":-540,"elapsed":64673,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"17518777-0c5a-4dbb-f61e-26c823e74ba7"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [01:03<00:00,  7.87it/s]\n"]}],"source":["output_file = os.path.join(\".\", \"word2vec_wiki\")\n","# Word2Vec 클래스의 인스턴스 생성\n","w2v = Word2Vec(docs, output_file, device, n_neg_sample=10, iteration=3)"]},{"cell_type":"code","execution_count":210,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:34:34.615469Z","start_time":"2022-02-19T14:34:34.055502Z"},"id":"ufBxjKxN4WSp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646743460315,"user_tz":-540,"elapsed":28039,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"17f9479e-bff2-46df-87e2-bc8a097e69b9"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:27<00:00, 17.93it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["21635"]},"metadata":{},"execution_count":210}],"source":["# 학습 데이터 셋 및 데이터 로더 생성 (위에서 생성한 w2v의 attribute들을 argument에 적절히 넣기)\n","dataset = CustomDataset(docs, word2id, window_size=5)\n","\n","train_dataloader = DataLoader(\n","                    dataset, \n","                    batch_size = 64, \n","                    shuffle = True)\n","\n","len(train_dataloader)"]},{"cell_type":"code","execution_count":211,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:45:38.362817Z","start_time":"2022-02-19T14:34:37.382371Z"},"id":"9JBUrUJ34WSp","colab":{"base_uri":"https://localhost:8080/","height":606},"executionInfo":{"status":"error","timestamp":1646743973489,"user_tz":-540,"elapsed":508678,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}},"outputId":"f3605966-f1c6-483e-a6fb-75230f08c75e"},"outputs":[{"output_type":"stream","name":"stdout","text":["*****Epoch 0 Train Start*****\n","*****Epoch 0 Total Step 21635*****\n","Step: 500 Loss: 4905.0429 lr: 0.0198\n","Step: 1000 Loss: 4912.3737 lr: 0.0197\n","Step: 1500 Loss: 4919.2646 lr: 0.0195\n","Step: 2000 Loss: 4912.6352 lr: 0.0194\n","Step: 2500 Loss: 4914.3775 lr: 0.0192\n","Step: 3000 Loss: 4927.2595 lr: 0.0191\n","Step: 3500 Loss: 4925.0198 lr: 0.0189\n","Step: 4000 Loss: 4938.2958 lr: 0.0188\n","Step: 4500 Loss: 4908.6994 lr: 0.0186\n","Step: 5000 Loss: 4927.5628 lr: 0.0185\n","Step: 5500 Loss: 4914.4616 lr: 0.0183\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-211-d47ce37a6bb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-207-0605ec1c33e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# loss 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m# optimizer 업데이트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.58 GiB (GPU 0; 15.90 GiB total capacity; 5.14 GiB already allocated; 4.59 GiB free; 10.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# 학습\n","w2v.train(train_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"3uTIm4vJ4WSp"},"source":["### 유사한 단어 확인\n","- 사전에 존재하는 단어들과 유사한 단어를 검색해보자. Gensim 패키지는 유사 단어 외에도 단어간의 유사도를 계산하는 여러 함수를 제공한다. 실험을 통해 word2vec의 한계점을 발견했다면 아래에 markdown으로 작성해보자. \n","- [Gensim 패키지 document](https://radimrehurek.com/gensim/models/keyedvectors.html)"]},{"cell_type":"code","execution_count":212,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:47:59.605389Z","start_time":"2022-02-19T14:47:59.368925Z"},"id":"AKpBuVlP4WSp","executionInfo":{"status":"ok","timestamp":1646744066055,"user_tz":-540,"elapsed":438,"user":{"displayName":"Surim Jang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg8FiIVl3JhupFutwcdTzVwmVsw7jEDtlApQqfT4w=s64","userId":"05642501551323307651"}}},"outputs":[],"source":["import gensim"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:49:06.590460Z","start_time":"2022-02-19T14:49:05.174241Z"},"id":"AWTCodimsAq8"},"outputs":[],"source":["word_vectors = gensim.models.KeyedVectors.load_word2vec_format('임베딩 파일 경로', binary=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-19T14:49:11.324372Z","start_time":"2022-02-19T14:49:11.315429Z"},"id":"MLMh_evrsAq9"},"outputs":[],"source":["word_vectors.most_similar(positive=None)"]},{"cell_type":"markdown","source":["word2vec의 한계점은?"],"metadata":{"id":"X8lc8NQe4cT2"}},{"cell_type":"markdown","source":["Word2Vec는 예측 기반으로 단어 간 유추 작업 시, 임베딩 벡터가 윈도우 크기 내에서만 주변 단어를 고려하기 때문에 코퍼스의 전체적인 통계 정보를 반영하지 못합니다."],"metadata":{"id":"lEBRikPekvaV"}}],"metadata":{"accelerator":"GPU","colab":{"name":"Week3_1_assignment.ipynb","provenance":[{"file_id":"1gzWuikm5MQtHIUZg0z2kMrqqmy1bdMWI","timestamp":1646703185812}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"torch","language":"python","name":"torch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"}},"nbformat":4,"nbformat_minor":0}